{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Biblioteca PyQuery\n",
    "\n",
    "PyQuery nos permite executarmos consultas **jQuery** em documentos XML. A API é bastante similar ao **jQuery**.\n",
    "\n",
    "PyQuery utiliza **lxml** para manipulação rápida de documentos XML e HTML.\n",
    "\n",
    "Você pode conhecer mais detalhes sobre PyQuery em sua **[Documentação](https://pythonhosted.org/pyquery/)**\n",
    "\n",
    "Vamos agora executar alguns experimentos utilizando nossa página de testes: **[pythonwebscraping.netlify.com](https://pythonwebscraping.netlify.com/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca PyQuery como pq\n",
    "from pyquery import PyQuery as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\"/>\n",
      "\t<title>Web Scraping Tutorial com Python</title>\n",
      "\t<link rel=\"icon\" href=\"https://i.imgur.com/QOVnf5D.png\"/>\n",
      "\t<style>\n",
      "\t.python {\n",
      "\t\tcolor: purple;\n",
      "\t}\n",
      "\t#titulo {\n",
      "\t\ttext-transform: uppercase;\n",
      "\t}\n",
      "\ttable {\n",
      "\t  border-collapse: collapse;\n",
      "\t}\n",
      "\n",
      "\ttable, th, td {\n",
      "\t  border: 1px solid black;\n",
      "\t  padding: 3px;\n",
      "\t}\n",
      "\t</style>\n",
      "</head>\n",
      "<body>\n",
      "\t<h1>Web Scraping</h1>\n",
      "\t<h2>Estrutura Básica HTML</h2>\n",
      "\t<img src=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/_images/6.1.jpg\"/>\n",
      "\t<p>Aprendendo Web Scraping com <a href=\"https://www.python.org/\">Python</a>,\n",
      "\t<a href=\"https://github.com/psf/requests-html\">Requests-HTML</a>,\n",
      "\t<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Beautiful Soup</a> e\n",
      "\t<a href=\"https://scrapy.org/\">Scrapy</a>\n",
      "\t</p>\n",
      "\n",
      "\t<p>“Logic will get you from A to Z; imagination will get you everywhere.” <b>Albert Einstein</b></p>\n",
      "\t\n",
      "\t<h3 id=\"titulo\">Linguagens de Programação</h3>\n",
      "\t<ul>\n",
      "\t\t<li class=\"python\">Python</li>\n",
      "\t\t<li>Perl</li>\n",
      "\t\t<li>PHP</li>\n",
      "\t</ul> \n",
      "\t\n",
      "\t<h3 id=\"titulo\">Grandes Matemáticos</h3>\n",
      "\t<table>\n",
      "\t\t<tr>\n",
      "\t\t\t<th>Nome</th>\n",
      "\t\t\t<th>Sobrenome</th>\n",
      "\t\t\t<th>Email</th>\n",
      "\t\t</tr>\n",
      "\t\t<tr>\n",
      "\t\t\t<td>Alan</td>\n",
      "\t\t\t<td>Turing</td>\n",
      "\t\t\t<td>alan@turing.com</td>\n",
      "\t\t</tr>\n",
      "\t\t<tr>\n",
      "\t\t\t<td>John</td>\n",
      "\t\t\t<td>von Neumann</td>\n",
      "\t\t\t<td>john@voneumann.com</td>\n",
      "\t\t</tr>\n",
      "\t\t<tr>\n",
      "\t\t\t<td>Blaise</td>\n",
      "\t\t\t<td>Pascal</td>\n",
      "\t\t\t<td>blaise@pascal.com</td>\n",
      "\t\t</tr>\n",
      "\t</table>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Fazendo a requisição de nosso documento HTML\n",
    "d = pq(url='https://pythonwebscraping.netlify.com/')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3#titulo>, <h3#titulo>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando elementos com o id titulo\n",
    "d('#titulo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguagens de Programação\n",
      "Grandes Matemáticos\n"
     ]
    }
   ],
   "source": [
    "# Utilizando um for loop para imprimir o texto dos elementos de id titulo\n",
    "for t in d('#titulo'):\n",
    "    print(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li.python>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando elementos que possuam a classe python\n",
    "d('.python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo o texto contido no elemento de classe python\n",
    "d('.python').text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li.python>, <li>, <li>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando <li> do documento HTML\n",
    "d('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n",
      "Perl\n",
      "PHP\n"
     ]
    }
   ],
   "source": [
    "# Utilizamos um for loop para imprimir o texto dos elementos <li>\n",
    "for li in d('li'):\n",
    "    print(li.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td>, <td>, <td>, <td>, <td>, <td>, <td>, <td>, <td>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionandos todos os elementos <td> do documento\n",
    "d('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alan\n",
      "Turing\n",
      "alan@turing.com\n",
      "John\n",
      "von Neumann\n",
      "john@voneumann.com\n",
      "Blaise\n",
      "Pascal\n",
      "blaise@pascal.com\n"
     ]
    }
   ],
   "source": [
    "# Obtendo o texto de cada elemento <td>\n",
    "for td in d('td'):\n",
    "    print(td.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos selecionar apenas o primeiro link do documento\n",
    "d('a:first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://scrapy.org/'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos selecionar apenas o último e extrair o conteúdo do atributo 'href'\n",
    "d('a:last').attr('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.python.org/\n",
      "https://github.com/psf/requests-html\n",
      "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "https://scrapy.org/\n"
     ]
    }
   ],
   "source": [
    "# Podemos extrair todos os links da página\n",
    "for links in d('a'):\n",
    "    print(links.attrib['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a>, <a>, <a>, <a>, <b>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando as tags filhas do elemento <p>\n",
    "d('p').children() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>, <p>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d('p') # Selecionando todos os elementos <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a>, <a>, <a>, <a>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d('p').find('a') # Pesquisando a existência de elementos <a> dentro de <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.python.org/\n",
      "https://github.com/psf/requests-html\n",
      "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "https://scrapy.org/\n"
     ]
    }
   ],
   "source": [
    "# Novamento, podemos obter os links com um for loop\n",
    "for l in d('p').find('a'):\n",
    "    print(l.attrib['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a presença de determinada classe\n",
    "d('li').hasClass('python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table>\\n\\t\\t<tr>\\n\\t\\t\\t<th>Nome</th>\\n\\t\\t\\t<th>Sobrenome</th>\\n\\t\\t\\t<th>Email</th>\\n\\t\\t</tr>\\n\\t\\t<tr>\\n\\t\\t\\t<td>Alan</td>\\n\\t\\t\\t<td>Turing</td>\\n\\t\\t\\t<td>alan@turing.com</td>\\n\\t\\t</tr>\\n\\t\\t<tr>\\n\\t\\t\\t<td>John</td>\\n\\t\\t\\t<td>von Neumann</td>\\n\\t\\t\\t<td>john@voneumann.com</td>\\n\\t\\t</tr>\\n\\t\\t<tr>\\n\\t\\t\\t<td>Blaise</td>\\n\\t\\t\\t<td>Pascal</td>\\n\\t\\t\\t<td>blaise@pascal.com</td>\\n\\t\\t</tr>\\n\\t</table>'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# É possível selecionarmos um elemento e assim\n",
    "# Podemos obter sua representação HTML com o método outerHtml()\n",
    "d('table').outerHtml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>, <p>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando todos os elementos <p> do documento\n",
    "d('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aprendendo Web Scraping com <a href=\"https://www.python.org/\">Python</a>,\\n\\t<a href=\"https://github.com/psf/requests-html\">Requests-HTML</a>,\\n\\t<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Beautiful Soup</a> e\\n\\t<a href=\"https://scrapy.org/\">Scrapy</a>\\n\\t'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrando elementos por posição\n",
    "d('p').filter(lambda i: i == 0).html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Logic will get you from A to Z; imagination will get you everywhere.” <b>Albert Einstein</b>'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrando elementos por posição\n",
    "d('p').filter(lambda i: i == 1).html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Logic will get you from A to Z; imagination will get you everywhere.” <b>Albert Einstein</b>'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrando elementos por seu texto\n",
    "d('p').filter(lambda i: pq(this).text() == '“Logic will get you from A to Z; imagination will get you everywhere.” Albert Einstein').html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aprendendo Web Scraping com <a href=\"https://www.python.org/\">Python</a>,\\n\\t<a href=\"https://github.com/psf/requests-html\">Requests-HTML</a>,\\n\\t<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Beautiful Soup</a> e\\n\\t<a href=\"https://scrapy.org/\">Scrapy</a>\\n\\t'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrando elementos por seu texto\n",
    "d('p').filter(lambda i: pq(this).text() == 'Aprendendo Web Scraping com Python, Requests-HTML, Beautiful Soup e Scrapy').html()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
